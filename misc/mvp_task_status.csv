"phase","area","task_id","task","priority","status"
"1 - Data Model Cleanup","Naming & Standards","1.1","Confirm final naming conventions for keys and metrics (state_fips, county_fips, naics2, year, abs_*, qcew_*, bea_*, tri_*).","High","Complete"
"1 - Data Model Cleanup","Naming & Standards","1.2","Inventory all existing tables and columns via INFORMATION_SCHEMA.COLUMNS or local schema inspection.","High","Complete"
"1 - Data Model Cleanup","Naming & Standards","1.3","Create a small rename plan mapping old_name to new_name for keys and top metrics only.","High","Complete"
"1 - Data Model Cleanup","Source Tables","1.4","Apply canonical column names in ABS cleaning script/view (abs_emp, abs_firms, abs_payroll_usd, abs_receipts_usd).","High","Complete"
"1 - Data Model Cleanup","Source Tables","1.5","Apply canonical column names in QCEW cleaning script/view (qcew_emp, qcew_wages_usd, qcew_avg_weekly_wage_usd).","High","Complete"
"1 - Data Model Cleanup","Source Tables","1.6","Apply canonical column names in BEA cleaning script/view (bea_gdp_usd, naics2).","High","Complete"
"1 - Data Model Cleanup","Source Tables","1.7","Apply canonical column names in TRI aggregation script/view (tri_releases_lbs, naics2).","Medium","Complete"
"1 - Data Model Cleanup","Merged Model","1.8","Ensure merged dataset uses standardized keys (state_fips, county_fips, naics2, year) and source prefixes consistently.","High","Not Started"
"2 - Pipelines & DQ","DQ Framework","2.1","Create reusable dq_report helper and error/warning logging utilities.","High","Not Started"
"2 - Pipelines & DQ","ABS DQ","2.2","Implement ABS DQ checks (key uniqueness, FIPS format, non-negative metrics, payroll per employee sanity).","High","Not Started"
"2 - Pipelines & DQ","QCEW DQ","2.3","Implement QCEW DQ checks (key uniqueness, non-negative, wages vs avg weekly wage consistency).","High","Not Started"
"2 - Pipelines & DQ","BEA DQ","2.4","Implement BEA DQ checks (key uniqueness, non-negative GDP, GDP per employee sanity if employment exists).","Medium","Complete"
"2 - Pipelines & DQ","TRI DQ","2.5","Implement TRI DQ checks (key uniqueness, non-negative releases, extreme outlier detection).","Medium","Not Started"
"2 - Pipelines & DQ","Merged DQ","2.6","Implement merged-table DQ checks (cross-source employment ratios, payroll vs wages per employee, payroll_to_receipts, coverage by source).","High","Not Started"
"2 - Pipelines & DQ","Pipeline Integration","2.7","Wire DQ checks into main pipeline so errors fail the run and warnings are logged.","High","Not Started"
"3 - Metrics","Core Metrics","3.1","Compute cost metrics: qcew_wages_per_employee, abs_payroll_per_employee, qcew_avg_weekly_wage_usd.","High","Not Started"
"3 - Metrics","Core Metrics","3.2","Compute productivity metrics: gdp_per_employee using bea_gdp_usd and employment (ABS or BEA).","High","Not Started"
"3 - Metrics","Core Metrics","3.3","Compute receipts metrics: abs_receipts_per_firm and payroll_to_receipts ratio.","High","Not Started"
"3 - Metrics","ESG Metrics","3.4","If TRI present, compute tri_lbs_per_employee and tri_lbs_per_million_gdp.","Medium","Not Started"
"3 - Metrics","Metric Validation","3.5","Validate metric ranges and distributions (spot outliers, confirm realistic ranges).","Medium","Not Started"
"4 - Looker Studio","Data Source Setup","4.1","Publish finalized merged table to BigQuery (or CSV) for Looker Studio consumption.","High","Not Started"
"4 - Looker Studio","Data Source Setup","4.2","Re-import data into Looker Studio using the cleaned schema and finalized metrics.","High","Not Started"
"4 - Looker Studio","Dashboard Design","4.3","Configure filters for county, NAICS2, and year in Looker Studio.","High","Not Started"
"4 - Looker Studio","Dashboard Design","4.4","Create KPI tiles for GDP per employee, wages per employee, receipts per firm, payroll_to_receipts ratio.","High","Not Started"
"4 - Looker Studio","Dashboard Design","4.5","Add comparison visuals (e.g., bar/scatter of productivity vs cost by sector or county).","Medium","Not Started"
"4 - Looker Studio","Dashboard Design","4.6","If TRI available, add ESG section with TRI intensity metrics.","Medium","Not Started"
"4 - Looker Studio","Dashboard Polish","4.7","Apply basic formatting, titles, and short descriptions so dashboard is portfolio-ready.","Medium","Not Started"
"5 - GitHub","Repo Cleanup","5.1","Create legacy-main branch (or equivalent) from the current GitHub main to preserve history.","Medium","Not Started"
"5 - GitHub","Repo Cleanup","5.2","Set up a clean mvp-refresh branch with the updated data model, pipelines, and DQ checks.","High","Not Started"
"5 - GitHub","Repo Cleanup","5.3","Prune or reorganize folders so only the MVP-relevant code, notebooks, and docs are in the main tree.","Medium","Complete"
"5 - GitHub","Branch Promotion","5.4","Merge mvp-refresh into main (or rename branches) to make clean version the default.","High","Not Started"
"6 - Docs & Sharing","Documentation","6.1","Draft README with project overview, data sources, naming conventions, and how to run the pipeline.","High","Not Started"
"6 - Docs & Sharing","Documentation","6.2","Create a simple data dictionary for the merged dataset (column names, definitions, units).","Medium","Not Started"
"6 - Docs & Sharing","Documentation","6.3","Add a short architecture/pipeline diagram or description (ABS/QCEW/BEA/TRI → merge → metrics → dashboard).","Medium","Not Started"
"6 - Docs & Sharing","Portfolio Assets","6.4","Capture one or two screenshots of the Looker Studio dashboard for README and PDF summary.","Medium","Not Started"
"6 - Docs & Sharing","Portfolio Assets","6.5","Draft a one-page MVP summary (PDF or markdown) explaining business value and key metrics.","Medium","Not Started"
"6 - Docs & Sharing","Sharing","6.6","Write a short outreach/email template to share the RDM Datalab MVP with selected contacts.","Low","Not Started"
